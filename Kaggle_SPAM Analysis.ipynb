{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e91d7c21-8351-4281-a0e5-2302d5dbd815",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP) training to identify scam messages from Kaggle's SMS Spam Collection data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1184dbaa-1a99-462a-96f0-1e677aa65a69",
   "metadata": {},
   "source": [
    "## Initial setup of Python libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714300de-9adc-4b02-b7bb-665552b3b6bd",
   "metadata": {},
   "source": [
    "##### The SVC Algorithm used in analyzing UC Irvine's data set is defined as a function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe88406d-b72e-46b3-94d1-7f05e1c7d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pickle\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline\n",
    "\n",
    "# Function for preprocessing\n",
    "def transform_message(message):\n",
    "    message_not_punc = ''.join([char for char in message if char not in string.punctuation])\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    message_clean = [word.lower() for word in message_not_punc.split() if word.lower() not in stop_words]\n",
    "    return message_clean\n",
    "\n",
    "# Full pipeline function for the SVC Algorithm\n",
    "def spam_detection_pipeline(data, text_column, label_column):\n",
    "    # Drop rows with missing values in text_column or label_column\n",
    "    data = data.dropna(subset=[text_column, label_column])\n",
    "\n",
    "    # Vectorization: CountVectorizer -> TfidfTransformer\n",
    "    vectorizer = CountVectorizer(analyzer=transform_message)\n",
    "    X_counts = vectorizer.fit_transform(data[text_column])\n",
    "\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X_tfidf = tfidf_transformer.fit_transform(X_counts)\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_tfidf, \n",
    "        data[label_column], \n",
    "        test_size=0.3, \n",
    "        random_state=50\n",
    "    )\n",
    "    \n",
    "    # Train the SVM model\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    predictions = clf.predict(X_test)\n",
    "    \n",
    "    # Evaluation\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864c46f7-e0eb-4772-ae57-9c761f68bc8c",
   "metadata": {},
   "source": [
    "## Using the Support Vector Classification (SVC) algorithm-powered NLP to analyze the Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24231283-5afa-49b3-bbfb-eea5801e7ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load a new dataset (ensure it has 'message' and 'label' columns)\n",
    "new_data = pd.read_csv('Datasets/Kaggle_SPAM_cleaned.csv')\n",
    "print(new_data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc02518b-198b-4f15-ba37-0a0bb0c19dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      1426\n",
      "        spam       0.99      0.84      0.91       246\n",
      "\n",
      "    accuracy                           0.97      1672\n",
      "   macro avg       0.98      0.92      0.95      1672\n",
      "weighted avg       0.98      0.97      0.97      1672\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1424    2]\n",
      " [  40  206]]\n"
     ]
    }
   ],
   "source": [
    "# Run the pipeline\n",
    "spam_detection_pipeline(new_data, text_column='message', label_column='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3213619f-aff7-46d6-88a0-fbd0bc743ca9",
   "metadata": {},
   "source": [
    "## Saving the model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6f9d71a-0177-4b5f-ad59-b0a6e92cdbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'Datasets/Kaggle_SPAM_Model'\n",
    "# Train CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer=transform_message)\n",
    "X_counts = vectorizer.fit_transform(new_data['message'])  # Fitting the vectorizer\n",
    "\n",
    "# Train TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_tfidf = tfidf_transformer.fit_transform(X_counts)  # Fitting the TF-IDF transformer\n",
    "\n",
    "# Train the SVM model\n",
    "clf = SVC(kernel='linear', class_weight='balanced')\n",
    "clf.fit(X_tfidf, new_data['label'])\n",
    "\n",
    "with open(os.path.join(model_dir, 'vectorizer_dataset2.pkl'), 'wb') as vec_file:\n",
    "    pickle.dump(vectorizer, vec_file)\n",
    "\n",
    "with open(os.path.join(model_dir, 'tfidf_transformer_dataset2.pkl'), 'wb') as tfidf_file:\n",
    "    pickle.dump(tfidf_transformer, tfidf_file)\n",
    "\n",
    "with open(os.path.join(model_dir, 'svm_model_dataset2.pkl'), 'wb') as model_file:\n",
    "    pickle.dump(clf, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f2efb-3391-4fbd-8537-d4d3748baad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
